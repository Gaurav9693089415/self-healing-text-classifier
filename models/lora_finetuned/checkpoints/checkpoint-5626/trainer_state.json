{
  "best_global_step": 5626,
  "best_metric": 0.35068660974502563,
  "best_model_checkpoint": ".\\models\\lora_finetuned\\checkpoints\\checkpoint-5626",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5626,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007109847138286527,
      "grad_norm": 1.3474586009979248,
      "learning_rate": 4.9831141130465697e-05,
      "loss": 0.6903,
      "step": 20
    },
    {
      "epoch": 0.014219694276573054,
      "grad_norm": 1.953063726425171,
      "learning_rate": 4.965339495200854e-05,
      "loss": 0.6732,
      "step": 40
    },
    {
      "epoch": 0.02132954141485958,
      "grad_norm": 1.0809305906295776,
      "learning_rate": 4.947564877355137e-05,
      "loss": 0.6562,
      "step": 60
    },
    {
      "epoch": 0.028439388553146108,
      "grad_norm": 2.2562034130096436,
      "learning_rate": 4.929790259509421e-05,
      "loss": 0.6576,
      "step": 80
    },
    {
      "epoch": 0.03554923569143263,
      "grad_norm": 1.7286843061447144,
      "learning_rate": 4.912015641663704e-05,
      "loss": 0.6344,
      "step": 100
    },
    {
      "epoch": 0.04265908282971916,
      "grad_norm": 0.9851924180984497,
      "learning_rate": 4.894241023817988e-05,
      "loss": 0.6063,
      "step": 120
    },
    {
      "epoch": 0.049768929968005686,
      "grad_norm": 0.9537907838821411,
      "learning_rate": 4.876466405972272e-05,
      "loss": 0.6106,
      "step": 140
    },
    {
      "epoch": 0.056878777106292217,
      "grad_norm": 1.5998588800430298,
      "learning_rate": 4.8586917881265554e-05,
      "loss": 0.5866,
      "step": 160
    },
    {
      "epoch": 0.06398862424457874,
      "grad_norm": 0.8489026427268982,
      "learning_rate": 4.8409171702808395e-05,
      "loss": 0.5867,
      "step": 180
    },
    {
      "epoch": 0.07109847138286526,
      "grad_norm": 1.1502856016159058,
      "learning_rate": 4.823142552435123e-05,
      "loss": 0.579,
      "step": 200
    },
    {
      "epoch": 0.0782083185211518,
      "grad_norm": 0.9445785880088806,
      "learning_rate": 4.805367934589406e-05,
      "loss": 0.5476,
      "step": 220
    },
    {
      "epoch": 0.08531816565943832,
      "grad_norm": 1.9383867979049683,
      "learning_rate": 4.78759331674369e-05,
      "loss": 0.5362,
      "step": 240
    },
    {
      "epoch": 0.09242801279772485,
      "grad_norm": 1.1664479970932007,
      "learning_rate": 4.769818698897974e-05,
      "loss": 0.5331,
      "step": 260
    },
    {
      "epoch": 0.09953785993601137,
      "grad_norm": 2.852839708328247,
      "learning_rate": 4.752044081052258e-05,
      "loss": 0.5373,
      "step": 280
    },
    {
      "epoch": 0.10664770707429791,
      "grad_norm": 1.4390132427215576,
      "learning_rate": 4.734269463206542e-05,
      "loss": 0.4918,
      "step": 300
    },
    {
      "epoch": 0.11375755421258443,
      "grad_norm": 0.8085677027702332,
      "learning_rate": 4.716494845360825e-05,
      "loss": 0.504,
      "step": 320
    },
    {
      "epoch": 0.12086740135087096,
      "grad_norm": 1.3515349626541138,
      "learning_rate": 4.6987202275151086e-05,
      "loss": 0.4985,
      "step": 340
    },
    {
      "epoch": 0.12797724848915748,
      "grad_norm": 2.9853179454803467,
      "learning_rate": 4.680945609669392e-05,
      "loss": 0.5058,
      "step": 360
    },
    {
      "epoch": 0.135087095627444,
      "grad_norm": 1.1119409799575806,
      "learning_rate": 4.663170991823676e-05,
      "loss": 0.5251,
      "step": 380
    },
    {
      "epoch": 0.14219694276573053,
      "grad_norm": 2.218996286392212,
      "learning_rate": 4.64539637397796e-05,
      "loss": 0.4934,
      "step": 400
    },
    {
      "epoch": 0.14930678990401705,
      "grad_norm": 0.8380411863327026,
      "learning_rate": 4.6276217561322435e-05,
      "loss": 0.5062,
      "step": 420
    },
    {
      "epoch": 0.1564166370423036,
      "grad_norm": 1.2184964418411255,
      "learning_rate": 4.609847138286527e-05,
      "loss": 0.4705,
      "step": 440
    },
    {
      "epoch": 0.16352648418059013,
      "grad_norm": 1.8419673442840576,
      "learning_rate": 4.59207252044081e-05,
      "loss": 0.4617,
      "step": 460
    },
    {
      "epoch": 0.17063633131887665,
      "grad_norm": 0.8710469603538513,
      "learning_rate": 4.574297902595094e-05,
      "loss": 0.4669,
      "step": 480
    },
    {
      "epoch": 0.17774617845716317,
      "grad_norm": 2.341374635696411,
      "learning_rate": 4.5565232847493784e-05,
      "loss": 0.4734,
      "step": 500
    },
    {
      "epoch": 0.1848560255954497,
      "grad_norm": 1.3961372375488281,
      "learning_rate": 4.538748666903662e-05,
      "loss": 0.4275,
      "step": 520
    },
    {
      "epoch": 0.19196587273373622,
      "grad_norm": 0.7671663165092468,
      "learning_rate": 4.520974049057946e-05,
      "loss": 0.4501,
      "step": 540
    },
    {
      "epoch": 0.19907571987202274,
      "grad_norm": 1.1918728351593018,
      "learning_rate": 4.503199431212229e-05,
      "loss": 0.4565,
      "step": 560
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 1.951108455657959,
      "learning_rate": 4.4854248133665126e-05,
      "loss": 0.4358,
      "step": 580
    },
    {
      "epoch": 0.21329541414859582,
      "grad_norm": 1.9126518964767456,
      "learning_rate": 4.4676501955207966e-05,
      "loss": 0.5055,
      "step": 600
    },
    {
      "epoch": 0.22040526128688234,
      "grad_norm": 1.1378859281539917,
      "learning_rate": 4.44987557767508e-05,
      "loss": 0.4467,
      "step": 620
    },
    {
      "epoch": 0.22751510842516887,
      "grad_norm": 1.3176078796386719,
      "learning_rate": 4.432100959829364e-05,
      "loss": 0.4487,
      "step": 640
    },
    {
      "epoch": 0.2346249555634554,
      "grad_norm": 0.9590367674827576,
      "learning_rate": 4.4143263419836475e-05,
      "loss": 0.4601,
      "step": 660
    },
    {
      "epoch": 0.2417348027017419,
      "grad_norm": 1.1263188123703003,
      "learning_rate": 4.396551724137931e-05,
      "loss": 0.4004,
      "step": 680
    },
    {
      "epoch": 0.24884464984002844,
      "grad_norm": 3.0259041786193848,
      "learning_rate": 4.378777106292215e-05,
      "loss": 0.4706,
      "step": 700
    },
    {
      "epoch": 0.25595449697831496,
      "grad_norm": 1.1519176959991455,
      "learning_rate": 4.361002488446498e-05,
      "loss": 0.4124,
      "step": 720
    },
    {
      "epoch": 0.2630643441166015,
      "grad_norm": 1.459594964981079,
      "learning_rate": 4.3432278706007824e-05,
      "loss": 0.4326,
      "step": 740
    },
    {
      "epoch": 0.270174191254888,
      "grad_norm": 1.9175523519515991,
      "learning_rate": 4.3254532527550664e-05,
      "loss": 0.4163,
      "step": 760
    },
    {
      "epoch": 0.27728403839317456,
      "grad_norm": 1.5855793952941895,
      "learning_rate": 4.30767863490935e-05,
      "loss": 0.4222,
      "step": 780
    },
    {
      "epoch": 0.28439388553146105,
      "grad_norm": 0.794833779335022,
      "learning_rate": 4.289904017063633e-05,
      "loss": 0.4483,
      "step": 800
    },
    {
      "epoch": 0.2915037326697476,
      "grad_norm": 0.9743921160697937,
      "learning_rate": 4.2721293992179166e-05,
      "loss": 0.4172,
      "step": 820
    },
    {
      "epoch": 0.2986135798080341,
      "grad_norm": 1.1607235670089722,
      "learning_rate": 4.2543547813722007e-05,
      "loss": 0.4193,
      "step": 840
    },
    {
      "epoch": 0.30572342694632065,
      "grad_norm": 0.8774323463439941,
      "learning_rate": 4.236580163526485e-05,
      "loss": 0.3994,
      "step": 860
    },
    {
      "epoch": 0.3128332740846072,
      "grad_norm": 1.344369649887085,
      "learning_rate": 4.218805545680768e-05,
      "loss": 0.4186,
      "step": 880
    },
    {
      "epoch": 0.3199431212228937,
      "grad_norm": 1.3434733152389526,
      "learning_rate": 4.2010309278350515e-05,
      "loss": 0.4387,
      "step": 900
    },
    {
      "epoch": 0.32705296836118025,
      "grad_norm": 2.315657615661621,
      "learning_rate": 4.183256309989335e-05,
      "loss": 0.4371,
      "step": 920
    },
    {
      "epoch": 0.33416281549946675,
      "grad_norm": 1.0708812475204468,
      "learning_rate": 4.165481692143619e-05,
      "loss": 0.4391,
      "step": 940
    },
    {
      "epoch": 0.3412726626377533,
      "grad_norm": 1.3058180809020996,
      "learning_rate": 4.147707074297903e-05,
      "loss": 0.3903,
      "step": 960
    },
    {
      "epoch": 0.3483825097760398,
      "grad_norm": 3.7945749759674072,
      "learning_rate": 4.1299324564521864e-05,
      "loss": 0.4078,
      "step": 980
    },
    {
      "epoch": 0.35549235691432635,
      "grad_norm": 1.6066688299179077,
      "learning_rate": 4.1121578386064704e-05,
      "loss": 0.359,
      "step": 1000
    },
    {
      "epoch": 0.36260220405261284,
      "grad_norm": 1.3557208776474,
      "learning_rate": 4.094383220760754e-05,
      "loss": 0.339,
      "step": 1020
    },
    {
      "epoch": 0.3697120511908994,
      "grad_norm": 1.088144063949585,
      "learning_rate": 4.076608602915037e-05,
      "loss": 0.405,
      "step": 1040
    },
    {
      "epoch": 0.37682189832918594,
      "grad_norm": 0.8776066899299622,
      "learning_rate": 4.058833985069321e-05,
      "loss": 0.4101,
      "step": 1060
    },
    {
      "epoch": 0.38393174546747244,
      "grad_norm": 1.4206007719039917,
      "learning_rate": 4.041059367223605e-05,
      "loss": 0.439,
      "step": 1080
    },
    {
      "epoch": 0.391041592605759,
      "grad_norm": 1.8169053792953491,
      "learning_rate": 4.023284749377889e-05,
      "loss": 0.4009,
      "step": 1100
    },
    {
      "epoch": 0.3981514397440455,
      "grad_norm": 1.381511926651001,
      "learning_rate": 4.005510131532173e-05,
      "loss": 0.3919,
      "step": 1120
    },
    {
      "epoch": 0.40526128688233204,
      "grad_norm": 0.7764509320259094,
      "learning_rate": 3.9877355136864555e-05,
      "loss": 0.3905,
      "step": 1140
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 1.850640058517456,
      "learning_rate": 3.9699608958407396e-05,
      "loss": 0.4399,
      "step": 1160
    },
    {
      "epoch": 0.4194809811589051,
      "grad_norm": 0.9605478644371033,
      "learning_rate": 3.952186277995023e-05,
      "loss": 0.36,
      "step": 1180
    },
    {
      "epoch": 0.42659082829719164,
      "grad_norm": 2.3109841346740723,
      "learning_rate": 3.934411660149307e-05,
      "loss": 0.4127,
      "step": 1200
    },
    {
      "epoch": 0.43370067543547813,
      "grad_norm": 2.190322160720825,
      "learning_rate": 3.916637042303591e-05,
      "loss": 0.3582,
      "step": 1220
    },
    {
      "epoch": 0.4408105225737647,
      "grad_norm": 1.1412220001220703,
      "learning_rate": 3.8988624244578745e-05,
      "loss": 0.3758,
      "step": 1240
    },
    {
      "epoch": 0.4479203697120512,
      "grad_norm": 0.780918300151825,
      "learning_rate": 3.881087806612158e-05,
      "loss": 0.3745,
      "step": 1260
    },
    {
      "epoch": 0.45503021685033773,
      "grad_norm": 2.642225980758667,
      "learning_rate": 3.863313188766441e-05,
      "loss": 0.4192,
      "step": 1280
    },
    {
      "epoch": 0.46214006398862423,
      "grad_norm": 0.9988794326782227,
      "learning_rate": 3.845538570920725e-05,
      "loss": 0.3833,
      "step": 1300
    },
    {
      "epoch": 0.4692499111269108,
      "grad_norm": 1.899388074874878,
      "learning_rate": 3.8277639530750094e-05,
      "loss": 0.3747,
      "step": 1320
    },
    {
      "epoch": 0.4763597582651973,
      "grad_norm": 1.5987651348114014,
      "learning_rate": 3.809989335229293e-05,
      "loss": 0.4385,
      "step": 1340
    },
    {
      "epoch": 0.4834696054034838,
      "grad_norm": 1.3011363744735718,
      "learning_rate": 3.792214717383577e-05,
      "loss": 0.3907,
      "step": 1360
    },
    {
      "epoch": 0.4905794525417704,
      "grad_norm": 1.5865840911865234,
      "learning_rate": 3.77444009953786e-05,
      "loss": 0.4162,
      "step": 1380
    },
    {
      "epoch": 0.4976892996800569,
      "grad_norm": 2.425752639770508,
      "learning_rate": 3.7566654816921436e-05,
      "loss": 0.4672,
      "step": 1400
    },
    {
      "epoch": 0.5047991468183434,
      "grad_norm": 2.072936773300171,
      "learning_rate": 3.7388908638464276e-05,
      "loss": 0.4078,
      "step": 1420
    },
    {
      "epoch": 0.5119089939566299,
      "grad_norm": 1.0972703695297241,
      "learning_rate": 3.721116246000711e-05,
      "loss": 0.3725,
      "step": 1440
    },
    {
      "epoch": 0.5190188410949165,
      "grad_norm": 1.8581269979476929,
      "learning_rate": 3.703341628154995e-05,
      "loss": 0.3949,
      "step": 1460
    },
    {
      "epoch": 0.526128688233203,
      "grad_norm": 1.4831383228302002,
      "learning_rate": 3.6855670103092785e-05,
      "loss": 0.4161,
      "step": 1480
    },
    {
      "epoch": 0.5332385353714895,
      "grad_norm": 1.6369318962097168,
      "learning_rate": 3.667792392463562e-05,
      "loss": 0.3708,
      "step": 1500
    },
    {
      "epoch": 0.540348382509776,
      "grad_norm": 0.930073082447052,
      "learning_rate": 3.650017774617846e-05,
      "loss": 0.3421,
      "step": 1520
    },
    {
      "epoch": 0.5474582296480626,
      "grad_norm": 1.626429796218872,
      "learning_rate": 3.632243156772129e-05,
      "loss": 0.3918,
      "step": 1540
    },
    {
      "epoch": 0.5545680767863491,
      "grad_norm": 0.9180271029472351,
      "learning_rate": 3.6144685389264134e-05,
      "loss": 0.44,
      "step": 1560
    },
    {
      "epoch": 0.5616779239246357,
      "grad_norm": 0.9206374883651733,
      "learning_rate": 3.5966939210806974e-05,
      "loss": 0.3622,
      "step": 1580
    },
    {
      "epoch": 0.5687877710629221,
      "grad_norm": 1.165183186531067,
      "learning_rate": 3.578919303234981e-05,
      "loss": 0.3812,
      "step": 1600
    },
    {
      "epoch": 0.5758976182012087,
      "grad_norm": 1.0601145029067993,
      "learning_rate": 3.561144685389264e-05,
      "loss": 0.4248,
      "step": 1620
    },
    {
      "epoch": 0.5830074653394952,
      "grad_norm": 1.371669054031372,
      "learning_rate": 3.5433700675435476e-05,
      "loss": 0.3866,
      "step": 1640
    },
    {
      "epoch": 0.5901173124777818,
      "grad_norm": 1.3417136669158936,
      "learning_rate": 3.5255954496978316e-05,
      "loss": 0.3977,
      "step": 1660
    },
    {
      "epoch": 0.5972271596160682,
      "grad_norm": 2.421628475189209,
      "learning_rate": 3.507820831852116e-05,
      "loss": 0.3989,
      "step": 1680
    },
    {
      "epoch": 0.6043370067543548,
      "grad_norm": 1.0142625570297241,
      "learning_rate": 3.490046214006399e-05,
      "loss": 0.3507,
      "step": 1700
    },
    {
      "epoch": 0.6114468538926413,
      "grad_norm": 0.9237031936645508,
      "learning_rate": 3.4722715961606825e-05,
      "loss": 0.3335,
      "step": 1720
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 2.014084815979004,
      "learning_rate": 3.4544969783149665e-05,
      "loss": 0.3788,
      "step": 1740
    },
    {
      "epoch": 0.6256665481692144,
      "grad_norm": 1.0171840190887451,
      "learning_rate": 3.43672236046925e-05,
      "loss": 0.376,
      "step": 1760
    },
    {
      "epoch": 0.6327763953075008,
      "grad_norm": 0.8917628526687622,
      "learning_rate": 3.418947742623534e-05,
      "loss": 0.4302,
      "step": 1780
    },
    {
      "epoch": 0.6398862424457874,
      "grad_norm": 1.4104104042053223,
      "learning_rate": 3.4011731247778174e-05,
      "loss": 0.4253,
      "step": 1800
    },
    {
      "epoch": 0.646996089584074,
      "grad_norm": 1.0352703332901,
      "learning_rate": 3.3833985069321014e-05,
      "loss": 0.4027,
      "step": 1820
    },
    {
      "epoch": 0.6541059367223605,
      "grad_norm": 1.7382806539535522,
      "learning_rate": 3.365623889086385e-05,
      "loss": 0.3594,
      "step": 1840
    },
    {
      "epoch": 0.6612157838606469,
      "grad_norm": 1.5045217275619507,
      "learning_rate": 3.347849271240668e-05,
      "loss": 0.3861,
      "step": 1860
    },
    {
      "epoch": 0.6683256309989335,
      "grad_norm": 2.591618776321411,
      "learning_rate": 3.330074653394952e-05,
      "loss": 0.3598,
      "step": 1880
    },
    {
      "epoch": 0.67543547813722,
      "grad_norm": 0.9221744537353516,
      "learning_rate": 3.3123000355492357e-05,
      "loss": 0.3525,
      "step": 1900
    },
    {
      "epoch": 0.6825453252755066,
      "grad_norm": 1.1288682222366333,
      "learning_rate": 3.29452541770352e-05,
      "loss": 0.3393,
      "step": 1920
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.796082079410553,
      "learning_rate": 3.276750799857803e-05,
      "loss": 0.4202,
      "step": 1940
    },
    {
      "epoch": 0.6967650195520796,
      "grad_norm": 1.6573890447616577,
      "learning_rate": 3.2589761820120865e-05,
      "loss": 0.3477,
      "step": 1960
    },
    {
      "epoch": 0.7038748666903661,
      "grad_norm": 1.433719515800476,
      "learning_rate": 3.2412015641663706e-05,
      "loss": 0.3723,
      "step": 1980
    },
    {
      "epoch": 0.7109847138286527,
      "grad_norm": 1.4435986280441284,
      "learning_rate": 3.223426946320654e-05,
      "loss": 0.3191,
      "step": 2000
    },
    {
      "epoch": 0.7180945609669392,
      "grad_norm": 0.8651378750801086,
      "learning_rate": 3.205652328474938e-05,
      "loss": 0.3783,
      "step": 2020
    },
    {
      "epoch": 0.7252044081052257,
      "grad_norm": 1.5924466848373413,
      "learning_rate": 3.187877710629222e-05,
      "loss": 0.4241,
      "step": 2040
    },
    {
      "epoch": 0.7323142552435122,
      "grad_norm": 1.26629638671875,
      "learning_rate": 3.1701030927835054e-05,
      "loss": 0.3888,
      "step": 2060
    },
    {
      "epoch": 0.7394241023817988,
      "grad_norm": 1.3199198246002197,
      "learning_rate": 3.152328474937789e-05,
      "loss": 0.3551,
      "step": 2080
    },
    {
      "epoch": 0.7465339495200853,
      "grad_norm": 0.8771263360977173,
      "learning_rate": 3.134553857092073e-05,
      "loss": 0.3619,
      "step": 2100
    },
    {
      "epoch": 0.7536437966583719,
      "grad_norm": 1.4992789030075073,
      "learning_rate": 3.116779239246356e-05,
      "loss": 0.3877,
      "step": 2120
    },
    {
      "epoch": 0.7607536437966583,
      "grad_norm": 2.1355843544006348,
      "learning_rate": 3.0990046214006403e-05,
      "loss": 0.3627,
      "step": 2140
    },
    {
      "epoch": 0.7678634909349449,
      "grad_norm": 1.0398621559143066,
      "learning_rate": 3.081230003554924e-05,
      "loss": 0.3599,
      "step": 2160
    },
    {
      "epoch": 0.7749733380732314,
      "grad_norm": 1.4472126960754395,
      "learning_rate": 3.063455385709207e-05,
      "loss": 0.4337,
      "step": 2180
    },
    {
      "epoch": 0.782083185211518,
      "grad_norm": 3.1476705074310303,
      "learning_rate": 3.0456807678634912e-05,
      "loss": 0.3403,
      "step": 2200
    },
    {
      "epoch": 0.7891930323498044,
      "grad_norm": 2.305680990219116,
      "learning_rate": 3.0279061500177746e-05,
      "loss": 0.3977,
      "step": 2220
    },
    {
      "epoch": 0.796302879488091,
      "grad_norm": 1.0217777490615845,
      "learning_rate": 3.0101315321720586e-05,
      "loss": 0.4371,
      "step": 2240
    },
    {
      "epoch": 0.8034127266263775,
      "grad_norm": 2.3298981189727783,
      "learning_rate": 2.992356914326342e-05,
      "loss": 0.3691,
      "step": 2260
    },
    {
      "epoch": 0.8105225737646641,
      "grad_norm": 1.4344621896743774,
      "learning_rate": 2.9745822964806257e-05,
      "loss": 0.3508,
      "step": 2280
    },
    {
      "epoch": 0.8176324209029506,
      "grad_norm": 2.031064748764038,
      "learning_rate": 2.9568076786349098e-05,
      "loss": 0.4228,
      "step": 2300
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 1.1673235893249512,
      "learning_rate": 2.9390330607891932e-05,
      "loss": 0.3633,
      "step": 2320
    },
    {
      "epoch": 0.8318521151795236,
      "grad_norm": 1.6462939977645874,
      "learning_rate": 2.921258442943477e-05,
      "loss": 0.3833,
      "step": 2340
    },
    {
      "epoch": 0.8389619623178102,
      "grad_norm": 1.4582219123840332,
      "learning_rate": 2.9034838250977603e-05,
      "loss": 0.3933,
      "step": 2360
    },
    {
      "epoch": 0.8460718094560967,
      "grad_norm": 0.9047335982322693,
      "learning_rate": 2.8857092072520444e-05,
      "loss": 0.3628,
      "step": 2380
    },
    {
      "epoch": 0.8531816565943833,
      "grad_norm": 1.8330357074737549,
      "learning_rate": 2.867934589406328e-05,
      "loss": 0.3677,
      "step": 2400
    },
    {
      "epoch": 0.8602915037326697,
      "grad_norm": 1.3967269659042358,
      "learning_rate": 2.8501599715606115e-05,
      "loss": 0.367,
      "step": 2420
    },
    {
      "epoch": 0.8674013508709563,
      "grad_norm": 1.7471779584884644,
      "learning_rate": 2.8323853537148952e-05,
      "loss": 0.3704,
      "step": 2440
    },
    {
      "epoch": 0.8745111980092428,
      "grad_norm": 1.072501540184021,
      "learning_rate": 2.8146107358691786e-05,
      "loss": 0.4,
      "step": 2460
    },
    {
      "epoch": 0.8816210451475294,
      "grad_norm": 0.7759273648262024,
      "learning_rate": 2.7968361180234626e-05,
      "loss": 0.3634,
      "step": 2480
    },
    {
      "epoch": 0.8887308922858158,
      "grad_norm": 0.8852407336235046,
      "learning_rate": 2.7790615001777464e-05,
      "loss": 0.3876,
      "step": 2500
    },
    {
      "epoch": 0.8958407394241024,
      "grad_norm": 1.2144765853881836,
      "learning_rate": 2.7612868823320297e-05,
      "loss": 0.4284,
      "step": 2520
    },
    {
      "epoch": 0.9029505865623889,
      "grad_norm": 3.2081377506256104,
      "learning_rate": 2.7435122644863138e-05,
      "loss": 0.4065,
      "step": 2540
    },
    {
      "epoch": 0.9100604337006755,
      "grad_norm": 1.4727665185928345,
      "learning_rate": 2.7257376466405975e-05,
      "loss": 0.3664,
      "step": 2560
    },
    {
      "epoch": 0.917170280838962,
      "grad_norm": 2.292118549346924,
      "learning_rate": 2.707963028794881e-05,
      "loss": 0.4091,
      "step": 2580
    },
    {
      "epoch": 0.9242801279772485,
      "grad_norm": 2.3991222381591797,
      "learning_rate": 2.690188410949165e-05,
      "loss": 0.383,
      "step": 2600
    },
    {
      "epoch": 0.931389975115535,
      "grad_norm": 1.3821744918823242,
      "learning_rate": 2.672413793103448e-05,
      "loss": 0.3787,
      "step": 2620
    },
    {
      "epoch": 0.9384998222538216,
      "grad_norm": 1.5862141847610474,
      "learning_rate": 2.654639175257732e-05,
      "loss": 0.3893,
      "step": 2640
    },
    {
      "epoch": 0.9456096693921081,
      "grad_norm": 0.7071366906166077,
      "learning_rate": 2.636864557412016e-05,
      "loss": 0.4362,
      "step": 2660
    },
    {
      "epoch": 0.9527195165303946,
      "grad_norm": 1.4360531568527222,
      "learning_rate": 2.6190899395662992e-05,
      "loss": 0.3656,
      "step": 2680
    },
    {
      "epoch": 0.9598293636686811,
      "grad_norm": 1.0107733011245728,
      "learning_rate": 2.6013153217205833e-05,
      "loss": 0.3882,
      "step": 2700
    },
    {
      "epoch": 0.9669392108069677,
      "grad_norm": 1.8579351902008057,
      "learning_rate": 2.5835407038748667e-05,
      "loss": 0.3817,
      "step": 2720
    },
    {
      "epoch": 0.9740490579452542,
      "grad_norm": 1.146830677986145,
      "learning_rate": 2.5657660860291504e-05,
      "loss": 0.3733,
      "step": 2740
    },
    {
      "epoch": 0.9811589050835408,
      "grad_norm": 1.4748070240020752,
      "learning_rate": 2.5479914681834344e-05,
      "loss": 0.3849,
      "step": 2760
    },
    {
      "epoch": 0.9882687522218272,
      "grad_norm": 0.9669974446296692,
      "learning_rate": 2.5302168503377178e-05,
      "loss": 0.3541,
      "step": 2780
    },
    {
      "epoch": 0.9953785993601137,
      "grad_norm": 0.6511044502258301,
      "learning_rate": 2.5124422324920015e-05,
      "loss": 0.3563,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3670271337032318,
      "eval_runtime": 341.9805,
      "eval_samples_per_second": 14.621,
      "eval_steps_per_second": 0.915,
      "step": 2813
    },
    {
      "epoch": 1.0024884464984003,
      "grad_norm": 1.4597312211990356,
      "learning_rate": 2.4946676146462853e-05,
      "loss": 0.3485,
      "step": 2820
    },
    {
      "epoch": 1.0095982936366867,
      "grad_norm": 2.2233331203460693,
      "learning_rate": 2.476892996800569e-05,
      "loss": 0.4058,
      "step": 2840
    },
    {
      "epoch": 1.0167081407749734,
      "grad_norm": 2.47066330909729,
      "learning_rate": 2.4591183789548524e-05,
      "loss": 0.3321,
      "step": 2860
    },
    {
      "epoch": 1.0238179879132598,
      "grad_norm": 0.9857969880104065,
      "learning_rate": 2.4413437611091364e-05,
      "loss": 0.371,
      "step": 2880
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 0.7917209267616272,
      "learning_rate": 2.4235691432634198e-05,
      "loss": 0.3964,
      "step": 2900
    },
    {
      "epoch": 1.038037682189833,
      "grad_norm": 4.214601039886475,
      "learning_rate": 2.4057945254177036e-05,
      "loss": 0.4384,
      "step": 2920
    },
    {
      "epoch": 1.0451475293281194,
      "grad_norm": 0.9573069214820862,
      "learning_rate": 2.3880199075719873e-05,
      "loss": 0.3502,
      "step": 2940
    },
    {
      "epoch": 1.052257376466406,
      "grad_norm": 1.1752487421035767,
      "learning_rate": 2.370245289726271e-05,
      "loss": 0.3782,
      "step": 2960
    },
    {
      "epoch": 1.0593672236046925,
      "grad_norm": 2.817671775817871,
      "learning_rate": 2.3524706718805547e-05,
      "loss": 0.4004,
      "step": 2980
    },
    {
      "epoch": 1.066477070742979,
      "grad_norm": 1.0185506343841553,
      "learning_rate": 2.3346960540348384e-05,
      "loss": 0.3418,
      "step": 3000
    },
    {
      "epoch": 1.0735869178812656,
      "grad_norm": 0.9263753294944763,
      "learning_rate": 2.316921436189122e-05,
      "loss": 0.4492,
      "step": 3020
    },
    {
      "epoch": 1.080696765019552,
      "grad_norm": 1.0989868640899658,
      "learning_rate": 2.2991468183434056e-05,
      "loss": 0.3466,
      "step": 3040
    },
    {
      "epoch": 1.0878066121578387,
      "grad_norm": 1.138700008392334,
      "learning_rate": 2.2813722004976896e-05,
      "loss": 0.3327,
      "step": 3060
    },
    {
      "epoch": 1.0949164592961251,
      "grad_norm": 2.985260009765625,
      "learning_rate": 2.263597582651973e-05,
      "loss": 0.3955,
      "step": 3080
    },
    {
      "epoch": 1.1020263064344116,
      "grad_norm": 0.9156856536865234,
      "learning_rate": 2.2458229648062567e-05,
      "loss": 0.3609,
      "step": 3100
    },
    {
      "epoch": 1.1091361535726982,
      "grad_norm": 1.4456982612609863,
      "learning_rate": 2.2280483469605405e-05,
      "loss": 0.355,
      "step": 3120
    },
    {
      "epoch": 1.1162460007109847,
      "grad_norm": 1.0693268775939941,
      "learning_rate": 2.210273729114824e-05,
      "loss": 0.3672,
      "step": 3140
    },
    {
      "epoch": 1.1233558478492713,
      "grad_norm": 1.4227473735809326,
      "learning_rate": 2.192499111269108e-05,
      "loss": 0.4047,
      "step": 3160
    },
    {
      "epoch": 1.1304656949875578,
      "grad_norm": 1.300047755241394,
      "learning_rate": 2.1747244934233916e-05,
      "loss": 0.3838,
      "step": 3180
    },
    {
      "epoch": 1.1375755421258442,
      "grad_norm": 4.110287189483643,
      "learning_rate": 2.156949875577675e-05,
      "loss": 0.3639,
      "step": 3200
    },
    {
      "epoch": 1.1446853892641309,
      "grad_norm": 3.4727957248687744,
      "learning_rate": 2.1391752577319587e-05,
      "loss": 0.4233,
      "step": 3220
    },
    {
      "epoch": 1.1517952364024173,
      "grad_norm": 3.2663307189941406,
      "learning_rate": 2.1214006398862428e-05,
      "loss": 0.3955,
      "step": 3240
    },
    {
      "epoch": 1.158905083540704,
      "grad_norm": 1.4052075147628784,
      "learning_rate": 2.1036260220405262e-05,
      "loss": 0.3582,
      "step": 3260
    },
    {
      "epoch": 1.1660149306789904,
      "grad_norm": 2.5795838832855225,
      "learning_rate": 2.08585140419481e-05,
      "loss": 0.35,
      "step": 3280
    },
    {
      "epoch": 1.1731247778172769,
      "grad_norm": 1.1940802335739136,
      "learning_rate": 2.0680767863490936e-05,
      "loss": 0.3805,
      "step": 3300
    },
    {
      "epoch": 1.1802346249555635,
      "grad_norm": 1.1970466375350952,
      "learning_rate": 2.050302168503377e-05,
      "loss": 0.3555,
      "step": 3320
    },
    {
      "epoch": 1.18734447209385,
      "grad_norm": 2.4221255779266357,
      "learning_rate": 2.032527550657661e-05,
      "loss": 0.375,
      "step": 3340
    },
    {
      "epoch": 1.1944543192321366,
      "grad_norm": 1.7302541732788086,
      "learning_rate": 2.0147529328119448e-05,
      "loss": 0.4317,
      "step": 3360
    },
    {
      "epoch": 1.201564166370423,
      "grad_norm": 0.8237122893333435,
      "learning_rate": 1.9969783149662282e-05,
      "loss": 0.3588,
      "step": 3380
    },
    {
      "epoch": 1.2086740135087095,
      "grad_norm": 1.7519527673721313,
      "learning_rate": 1.979203697120512e-05,
      "loss": 0.3882,
      "step": 3400
    },
    {
      "epoch": 1.2157838606469962,
      "grad_norm": 0.9974039196968079,
      "learning_rate": 1.9614290792747956e-05,
      "loss": 0.368,
      "step": 3420
    },
    {
      "epoch": 1.2228937077852826,
      "grad_norm": 1.418979287147522,
      "learning_rate": 1.9436544614290794e-05,
      "loss": 0.3712,
      "step": 3440
    },
    {
      "epoch": 1.230003554923569,
      "grad_norm": 3.166991710662842,
      "learning_rate": 1.925879843583363e-05,
      "loss": 0.3401,
      "step": 3460
    },
    {
      "epoch": 1.2371134020618557,
      "grad_norm": 0.8281844854354858,
      "learning_rate": 1.9081052257376468e-05,
      "loss": 0.3968,
      "step": 3480
    },
    {
      "epoch": 1.2442232492001422,
      "grad_norm": 1.3085129261016846,
      "learning_rate": 1.8903306078919302e-05,
      "loss": 0.3529,
      "step": 3500
    },
    {
      "epoch": 1.2513330963384286,
      "grad_norm": 1.1822959184646606,
      "learning_rate": 1.8725559900462143e-05,
      "loss": 0.3595,
      "step": 3520
    },
    {
      "epoch": 1.2584429434767153,
      "grad_norm": 1.7387616634368896,
      "learning_rate": 1.8547813722004976e-05,
      "loss": 0.3674,
      "step": 3540
    },
    {
      "epoch": 1.2655527906150017,
      "grad_norm": 1.6433334350585938,
      "learning_rate": 1.8370067543547814e-05,
      "loss": 0.4109,
      "step": 3560
    },
    {
      "epoch": 1.2726626377532884,
      "grad_norm": 1.5996369123458862,
      "learning_rate": 1.819232136509065e-05,
      "loss": 0.3936,
      "step": 3580
    },
    {
      "epoch": 1.2797724848915748,
      "grad_norm": 0.7556619048118591,
      "learning_rate": 1.8014575186633488e-05,
      "loss": 0.417,
      "step": 3600
    },
    {
      "epoch": 1.2868823320298612,
      "grad_norm": 1.9551268815994263,
      "learning_rate": 1.7836829008176325e-05,
      "loss": 0.3701,
      "step": 3620
    },
    {
      "epoch": 1.293992179168148,
      "grad_norm": 0.8775224685668945,
      "learning_rate": 1.7659082829719163e-05,
      "loss": 0.3247,
      "step": 3640
    },
    {
      "epoch": 1.3011020263064343,
      "grad_norm": 1.5124902725219727,
      "learning_rate": 1.7481336651261996e-05,
      "loss": 0.3884,
      "step": 3660
    },
    {
      "epoch": 1.308211873444721,
      "grad_norm": 1.0616416931152344,
      "learning_rate": 1.7303590472804834e-05,
      "loss": 0.3768,
      "step": 3680
    },
    {
      "epoch": 1.3153217205830074,
      "grad_norm": 1.1413437128067017,
      "learning_rate": 1.7125844294347674e-05,
      "loss": 0.3185,
      "step": 3700
    },
    {
      "epoch": 1.3224315677212939,
      "grad_norm": 1.1148121356964111,
      "learning_rate": 1.6948098115890508e-05,
      "loss": 0.3753,
      "step": 3720
    },
    {
      "epoch": 1.3295414148595806,
      "grad_norm": 0.7919474244117737,
      "learning_rate": 1.6770351937433345e-05,
      "loss": 0.3743,
      "step": 3740
    },
    {
      "epoch": 1.336651261997867,
      "grad_norm": 0.9907968640327454,
      "learning_rate": 1.6592605758976183e-05,
      "loss": 0.3431,
      "step": 3760
    },
    {
      "epoch": 1.3437611091361537,
      "grad_norm": 2.2402005195617676,
      "learning_rate": 1.641485958051902e-05,
      "loss": 0.3264,
      "step": 3780
    },
    {
      "epoch": 1.35087095627444,
      "grad_norm": 4.062816143035889,
      "learning_rate": 1.6237113402061857e-05,
      "loss": 0.3728,
      "step": 3800
    },
    {
      "epoch": 1.3579808034127265,
      "grad_norm": 0.8370519876480103,
      "learning_rate": 1.6059367223604694e-05,
      "loss": 0.3439,
      "step": 3820
    },
    {
      "epoch": 1.3650906505510132,
      "grad_norm": 1.4988435506820679,
      "learning_rate": 1.5881621045147528e-05,
      "loss": 0.348,
      "step": 3840
    },
    {
      "epoch": 1.3722004976892996,
      "grad_norm": 3.813512086868286,
      "learning_rate": 1.5703874866690366e-05,
      "loss": 0.356,
      "step": 3860
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 2.338824987411499,
      "learning_rate": 1.5526128688233206e-05,
      "loss": 0.3536,
      "step": 3880
    },
    {
      "epoch": 1.3864201919658727,
      "grad_norm": 2.300691843032837,
      "learning_rate": 1.534838250977604e-05,
      "loss": 0.3679,
      "step": 3900
    },
    {
      "epoch": 1.3935300391041592,
      "grad_norm": 1.6653872728347778,
      "learning_rate": 1.5170636331318877e-05,
      "loss": 0.3733,
      "step": 3920
    },
    {
      "epoch": 1.4006398862424458,
      "grad_norm": 1.138741374015808,
      "learning_rate": 1.4992890152861713e-05,
      "loss": 0.3518,
      "step": 3940
    },
    {
      "epoch": 1.4077497333807323,
      "grad_norm": 1.3320170640945435,
      "learning_rate": 1.4815143974404552e-05,
      "loss": 0.3894,
      "step": 3960
    },
    {
      "epoch": 1.414859580519019,
      "grad_norm": 2.7186877727508545,
      "learning_rate": 1.4637397795947389e-05,
      "loss": 0.3976,
      "step": 3980
    },
    {
      "epoch": 1.4219694276573054,
      "grad_norm": 1.4009369611740112,
      "learning_rate": 1.4459651617490225e-05,
      "loss": 0.3414,
      "step": 4000
    },
    {
      "epoch": 1.4290792747955918,
      "grad_norm": 1.91374933719635,
      "learning_rate": 1.428190543903306e-05,
      "loss": 0.4358,
      "step": 4020
    },
    {
      "epoch": 1.4361891219338785,
      "grad_norm": 0.6407142877578735,
      "learning_rate": 1.4104159260575897e-05,
      "loss": 0.3222,
      "step": 4040
    },
    {
      "epoch": 1.443298969072165,
      "grad_norm": 1.1354671716690063,
      "learning_rate": 1.3926413082118736e-05,
      "loss": 0.3701,
      "step": 4060
    },
    {
      "epoch": 1.4504088162104516,
      "grad_norm": 0.9440386295318604,
      "learning_rate": 1.3748666903661572e-05,
      "loss": 0.4022,
      "step": 4080
    },
    {
      "epoch": 1.457518663348738,
      "grad_norm": 2.282177448272705,
      "learning_rate": 1.3570920725204409e-05,
      "loss": 0.3267,
      "step": 4100
    },
    {
      "epoch": 1.4646285104870245,
      "grad_norm": 1.647484302520752,
      "learning_rate": 1.3393174546747245e-05,
      "loss": 0.37,
      "step": 4120
    },
    {
      "epoch": 1.4717383576253111,
      "grad_norm": 2.6865642070770264,
      "learning_rate": 1.3215428368290083e-05,
      "loss": 0.3874,
      "step": 4140
    },
    {
      "epoch": 1.4788482047635976,
      "grad_norm": 0.7184346318244934,
      "learning_rate": 1.3037682189832919e-05,
      "loss": 0.376,
      "step": 4160
    },
    {
      "epoch": 1.4859580519018842,
      "grad_norm": 1.9321908950805664,
      "learning_rate": 1.2868823320298615e-05,
      "loss": 0.3671,
      "step": 4180
    },
    {
      "epoch": 1.4930678990401707,
      "grad_norm": 0.8242185115814209,
      "learning_rate": 1.269107714184145e-05,
      "loss": 0.3604,
      "step": 4200
    },
    {
      "epoch": 1.5001777461784571,
      "grad_norm": 1.1430071592330933,
      "learning_rate": 1.2513330963384288e-05,
      "loss": 0.3349,
      "step": 4220
    },
    {
      "epoch": 1.5072875933167436,
      "grad_norm": 1.2733365297317505,
      "learning_rate": 1.2335584784927125e-05,
      "loss": 0.4205,
      "step": 4240
    },
    {
      "epoch": 1.5143974404550302,
      "grad_norm": 1.3083961009979248,
      "learning_rate": 1.215783860646996e-05,
      "loss": 0.337,
      "step": 4260
    },
    {
      "epoch": 1.5215072875933169,
      "grad_norm": 1.408383846282959,
      "learning_rate": 1.1980092428012798e-05,
      "loss": 0.3461,
      "step": 4280
    },
    {
      "epoch": 1.5286171347316033,
      "grad_norm": 2.5752670764923096,
      "learning_rate": 1.1802346249555635e-05,
      "loss": 0.3276,
      "step": 4300
    },
    {
      "epoch": 1.5357269818698898,
      "grad_norm": 0.9482957720756531,
      "learning_rate": 1.1624600071098472e-05,
      "loss": 0.4038,
      "step": 4320
    },
    {
      "epoch": 1.5428368290081762,
      "grad_norm": 1.0064219236373901,
      "learning_rate": 1.1446853892641308e-05,
      "loss": 0.3762,
      "step": 4340
    },
    {
      "epoch": 1.5499466761464629,
      "grad_norm": 2.2025585174560547,
      "learning_rate": 1.1269107714184147e-05,
      "loss": 0.3133,
      "step": 4360
    },
    {
      "epoch": 1.5570565232847495,
      "grad_norm": 1.274440050125122,
      "learning_rate": 1.1091361535726982e-05,
      "loss": 0.3054,
      "step": 4380
    },
    {
      "epoch": 1.564166370423036,
      "grad_norm": 1.060327172279358,
      "learning_rate": 1.0913615357269818e-05,
      "loss": 0.3977,
      "step": 4400
    },
    {
      "epoch": 1.5712762175613224,
      "grad_norm": 0.9470155835151672,
      "learning_rate": 1.0735869178812657e-05,
      "loss": 0.4021,
      "step": 4420
    },
    {
      "epoch": 1.5783860646996088,
      "grad_norm": 2.653132915496826,
      "learning_rate": 1.0558123000355492e-05,
      "loss": 0.3122,
      "step": 4440
    },
    {
      "epoch": 1.5854959118378955,
      "grad_norm": 1.624746561050415,
      "learning_rate": 1.038037682189833e-05,
      "loss": 0.4065,
      "step": 4460
    },
    {
      "epoch": 1.5926057589761822,
      "grad_norm": 1.5614781379699707,
      "learning_rate": 1.0202630643441167e-05,
      "loss": 0.3846,
      "step": 4480
    },
    {
      "epoch": 1.5997156061144686,
      "grad_norm": 2.7267239093780518,
      "learning_rate": 1.0024884464984004e-05,
      "loss": 0.375,
      "step": 4500
    },
    {
      "epoch": 1.606825453252755,
      "grad_norm": 2.259625196456909,
      "learning_rate": 9.84713828652684e-06,
      "loss": 0.4062,
      "step": 4520
    },
    {
      "epoch": 1.6139353003910415,
      "grad_norm": 2.5751330852508545,
      "learning_rate": 9.669392108069677e-06,
      "loss": 0.3903,
      "step": 4540
    },
    {
      "epoch": 1.6210451475293282,
      "grad_norm": 3.402519464492798,
      "learning_rate": 9.491645929612514e-06,
      "loss": 0.4088,
      "step": 4560
    },
    {
      "epoch": 1.6281549946676146,
      "grad_norm": 0.7186712026596069,
      "learning_rate": 9.31389975115535e-06,
      "loss": 0.3408,
      "step": 4580
    },
    {
      "epoch": 1.6352648418059013,
      "grad_norm": 1.4417182207107544,
      "learning_rate": 9.136153572698187e-06,
      "loss": 0.3346,
      "step": 4600
    },
    {
      "epoch": 1.6423746889441877,
      "grad_norm": 1.02915620803833,
      "learning_rate": 8.958407394241024e-06,
      "loss": 0.3712,
      "step": 4620
    },
    {
      "epoch": 1.6494845360824741,
      "grad_norm": 1.4969826936721802,
      "learning_rate": 8.780661215783861e-06,
      "loss": 0.3582,
      "step": 4640
    },
    {
      "epoch": 1.6565943832207608,
      "grad_norm": 3.427839756011963,
      "learning_rate": 8.602915037326697e-06,
      "loss": 0.3636,
      "step": 4660
    },
    {
      "epoch": 1.6637042303590472,
      "grad_norm": 1.9646742343902588,
      "learning_rate": 8.425168858869536e-06,
      "loss": 0.397,
      "step": 4680
    },
    {
      "epoch": 1.670814077497334,
      "grad_norm": 0.8195866346359253,
      "learning_rate": 8.247422680412371e-06,
      "loss": 0.3846,
      "step": 4700
    },
    {
      "epoch": 1.6779239246356203,
      "grad_norm": 1.3325015306472778,
      "learning_rate": 8.069676501955209e-06,
      "loss": 0.3542,
      "step": 4720
    },
    {
      "epoch": 1.6850337717739068,
      "grad_norm": 1.3669308423995972,
      "learning_rate": 7.891930323498046e-06,
      "loss": 0.3781,
      "step": 4740
    },
    {
      "epoch": 1.6921436189121932,
      "grad_norm": 3.3851478099823,
      "learning_rate": 7.714184145040881e-06,
      "loss": 0.3796,
      "step": 4760
    },
    {
      "epoch": 1.6992534660504799,
      "grad_norm": 1.1995128393173218,
      "learning_rate": 7.536437966583719e-06,
      "loss": 0.3802,
      "step": 4780
    },
    {
      "epoch": 1.7063633131887666,
      "grad_norm": 2.576868772506714,
      "learning_rate": 7.358691788126555e-06,
      "loss": 0.3811,
      "step": 4800
    },
    {
      "epoch": 1.713473160327053,
      "grad_norm": 2.404188871383667,
      "learning_rate": 7.180945609669393e-06,
      "loss": 0.4177,
      "step": 4820
    },
    {
      "epoch": 1.7205830074653394,
      "grad_norm": 2.1706910133361816,
      "learning_rate": 7.003199431212229e-06,
      "loss": 0.4078,
      "step": 4840
    },
    {
      "epoch": 1.7276928546036259,
      "grad_norm": 1.0001063346862793,
      "learning_rate": 6.825453252755067e-06,
      "loss": 0.3867,
      "step": 4860
    },
    {
      "epoch": 1.7348027017419125,
      "grad_norm": 1.9217406511306763,
      "learning_rate": 6.647707074297903e-06,
      "loss": 0.3495,
      "step": 4880
    },
    {
      "epoch": 1.7419125488801992,
      "grad_norm": 1.1080820560455322,
      "learning_rate": 6.46996089584074e-06,
      "loss": 0.3513,
      "step": 4900
    },
    {
      "epoch": 1.7490223960184856,
      "grad_norm": 1.8635224103927612,
      "learning_rate": 6.292214717383577e-06,
      "loss": 0.3107,
      "step": 4920
    },
    {
      "epoch": 1.756132243156772,
      "grad_norm": 1.2641247510910034,
      "learning_rate": 6.114468538926413e-06,
      "loss": 0.3649,
      "step": 4940
    },
    {
      "epoch": 1.7632420902950585,
      "grad_norm": 0.9827403426170349,
      "learning_rate": 5.93672236046925e-06,
      "loss": 0.3086,
      "step": 4960
    },
    {
      "epoch": 1.7703519374333452,
      "grad_norm": 1.2644158601760864,
      "learning_rate": 5.758976182012088e-06,
      "loss": 0.343,
      "step": 4980
    },
    {
      "epoch": 1.7774617845716318,
      "grad_norm": 1.2010973691940308,
      "learning_rate": 5.581230003554923e-06,
      "loss": 0.3172,
      "step": 5000
    },
    {
      "epoch": 1.7845716317099183,
      "grad_norm": 1.9741151332855225,
      "learning_rate": 5.40348382509776e-06,
      "loss": 0.3271,
      "step": 5020
    },
    {
      "epoch": 1.7916814788482047,
      "grad_norm": 3.2871639728546143,
      "learning_rate": 5.225737646640598e-06,
      "loss": 0.3715,
      "step": 5040
    },
    {
      "epoch": 1.7987913259864912,
      "grad_norm": 0.8852137923240662,
      "learning_rate": 5.047991468183434e-06,
      "loss": 0.3981,
      "step": 5060
    },
    {
      "epoch": 1.8059011731247778,
      "grad_norm": 0.8354028463363647,
      "learning_rate": 4.870245289726271e-06,
      "loss": 0.3629,
      "step": 5080
    },
    {
      "epoch": 1.8130110202630645,
      "grad_norm": 1.0003658533096313,
      "learning_rate": 4.692499111269108e-06,
      "loss": 0.3542,
      "step": 5100
    },
    {
      "epoch": 1.820120867401351,
      "grad_norm": 1.3855392932891846,
      "learning_rate": 4.514752932811945e-06,
      "loss": 0.3338,
      "step": 5120
    },
    {
      "epoch": 1.8272307145396374,
      "grad_norm": 1.1595524549484253,
      "learning_rate": 4.337006754354782e-06,
      "loss": 0.3688,
      "step": 5140
    },
    {
      "epoch": 1.8343405616779238,
      "grad_norm": 3.346384286880493,
      "learning_rate": 4.1592605758976186e-06,
      "loss": 0.4108,
      "step": 5160
    },
    {
      "epoch": 1.8414504088162105,
      "grad_norm": 1.3494105339050293,
      "learning_rate": 3.981514397440455e-06,
      "loss": 0.311,
      "step": 5180
    },
    {
      "epoch": 1.8485602559544971,
      "grad_norm": 1.0711325407028198,
      "learning_rate": 3.8037682189832918e-06,
      "loss": 0.3818,
      "step": 5200
    },
    {
      "epoch": 1.8556701030927836,
      "grad_norm": 2.101483106613159,
      "learning_rate": 3.6260220405261286e-06,
      "loss": 0.3574,
      "step": 5220
    },
    {
      "epoch": 1.86277995023107,
      "grad_norm": 1.535262107849121,
      "learning_rate": 3.448275862068966e-06,
      "loss": 0.4154,
      "step": 5240
    },
    {
      "epoch": 1.8698897973693565,
      "grad_norm": 1.9579448699951172,
      "learning_rate": 3.2705296836118026e-06,
      "loss": 0.375,
      "step": 5260
    },
    {
      "epoch": 1.8769996445076431,
      "grad_norm": 1.2984822988510132,
      "learning_rate": 3.0927835051546395e-06,
      "loss": 0.3388,
      "step": 5280
    },
    {
      "epoch": 1.8841094916459296,
      "grad_norm": 1.8338449001312256,
      "learning_rate": 2.915037326697476e-06,
      "loss": 0.3755,
      "step": 5300
    },
    {
      "epoch": 1.8912193387842162,
      "grad_norm": 2.9920406341552734,
      "learning_rate": 2.737291148240313e-06,
      "loss": 0.3581,
      "step": 5320
    },
    {
      "epoch": 1.8983291859225027,
      "grad_norm": 1.6234394311904907,
      "learning_rate": 2.55954496978315e-06,
      "loss": 0.3605,
      "step": 5340
    },
    {
      "epoch": 1.905439033060789,
      "grad_norm": 0.9321906566619873,
      "learning_rate": 2.3817987913259867e-06,
      "loss": 0.3323,
      "step": 5360
    },
    {
      "epoch": 1.9125488801990758,
      "grad_norm": 1.3686764240264893,
      "learning_rate": 2.2040526128688235e-06,
      "loss": 0.3956,
      "step": 5380
    },
    {
      "epoch": 1.9196587273373622,
      "grad_norm": 0.5107648372650146,
      "learning_rate": 2.02630643441166e-06,
      "loss": 0.3407,
      "step": 5400
    },
    {
      "epoch": 1.9267685744756489,
      "grad_norm": 1.0427583456039429,
      "learning_rate": 1.848560255954497e-06,
      "loss": 0.4001,
      "step": 5420
    },
    {
      "epoch": 1.9338784216139353,
      "grad_norm": 3.090278387069702,
      "learning_rate": 1.670814077497334e-06,
      "loss": 0.3785,
      "step": 5440
    },
    {
      "epoch": 1.9409882687522217,
      "grad_norm": 3.6143486499786377,
      "learning_rate": 1.4930678990401706e-06,
      "loss": 0.4019,
      "step": 5460
    },
    {
      "epoch": 1.9480981158905084,
      "grad_norm": 3.380997896194458,
      "learning_rate": 1.3153217205830076e-06,
      "loss": 0.3369,
      "step": 5480
    },
    {
      "epoch": 1.9552079630287948,
      "grad_norm": 1.2101564407348633,
      "learning_rate": 1.1375755421258442e-06,
      "loss": 0.3805,
      "step": 5500
    },
    {
      "epoch": 1.9623178101670815,
      "grad_norm": 0.7952025532722473,
      "learning_rate": 9.598293636686813e-07,
      "loss": 0.3118,
      "step": 5520
    },
    {
      "epoch": 1.969427657305368,
      "grad_norm": 2.442534923553467,
      "learning_rate": 7.82083185211518e-07,
      "loss": 0.4086,
      "step": 5540
    },
    {
      "epoch": 1.9765375044436544,
      "grad_norm": 0.6735942363739014,
      "learning_rate": 6.043370067543548e-07,
      "loss": 0.3347,
      "step": 5560
    },
    {
      "epoch": 1.9836473515819408,
      "grad_norm": 3.751056671142578,
      "learning_rate": 4.2659082829719167e-07,
      "loss": 0.3976,
      "step": 5580
    },
    {
      "epoch": 1.9907571987202275,
      "grad_norm": 1.49911630153656,
      "learning_rate": 2.4884464984002843e-07,
      "loss": 0.3936,
      "step": 5600
    },
    {
      "epoch": 1.9978670458585142,
      "grad_norm": 1.4815157651901245,
      "learning_rate": 7.109847138286527e-08,
      "loss": 0.3224,
      "step": 5620
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.35068660974502563,
      "eval_runtime": 342.0161,
      "eval_samples_per_second": 14.619,
      "eval_steps_per_second": 0.915,
      "step": 5626
    }
  ],
  "logging_steps": 20,
  "max_steps": 5626,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6063273308160000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
