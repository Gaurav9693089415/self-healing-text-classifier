{
  "best_global_step": 2813,
  "best_metric": 0.3670271337032318,
  "best_model_checkpoint": ".\\models\\lora_finetuned\\checkpoints\\checkpoint-2813",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2813,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007109847138286527,
      "grad_norm": 1.3474586009979248,
      "learning_rate": 4.9831141130465697e-05,
      "loss": 0.6903,
      "step": 20
    },
    {
      "epoch": 0.014219694276573054,
      "grad_norm": 1.953063726425171,
      "learning_rate": 4.965339495200854e-05,
      "loss": 0.6732,
      "step": 40
    },
    {
      "epoch": 0.02132954141485958,
      "grad_norm": 1.0809305906295776,
      "learning_rate": 4.947564877355137e-05,
      "loss": 0.6562,
      "step": 60
    },
    {
      "epoch": 0.028439388553146108,
      "grad_norm": 2.2562034130096436,
      "learning_rate": 4.929790259509421e-05,
      "loss": 0.6576,
      "step": 80
    },
    {
      "epoch": 0.03554923569143263,
      "grad_norm": 1.7286843061447144,
      "learning_rate": 4.912015641663704e-05,
      "loss": 0.6344,
      "step": 100
    },
    {
      "epoch": 0.04265908282971916,
      "grad_norm": 0.9851924180984497,
      "learning_rate": 4.894241023817988e-05,
      "loss": 0.6063,
      "step": 120
    },
    {
      "epoch": 0.049768929968005686,
      "grad_norm": 0.9537907838821411,
      "learning_rate": 4.876466405972272e-05,
      "loss": 0.6106,
      "step": 140
    },
    {
      "epoch": 0.056878777106292217,
      "grad_norm": 1.5998588800430298,
      "learning_rate": 4.8586917881265554e-05,
      "loss": 0.5866,
      "step": 160
    },
    {
      "epoch": 0.06398862424457874,
      "grad_norm": 0.8489026427268982,
      "learning_rate": 4.8409171702808395e-05,
      "loss": 0.5867,
      "step": 180
    },
    {
      "epoch": 0.07109847138286526,
      "grad_norm": 1.1502856016159058,
      "learning_rate": 4.823142552435123e-05,
      "loss": 0.579,
      "step": 200
    },
    {
      "epoch": 0.0782083185211518,
      "grad_norm": 0.9445785880088806,
      "learning_rate": 4.805367934589406e-05,
      "loss": 0.5476,
      "step": 220
    },
    {
      "epoch": 0.08531816565943832,
      "grad_norm": 1.9383867979049683,
      "learning_rate": 4.78759331674369e-05,
      "loss": 0.5362,
      "step": 240
    },
    {
      "epoch": 0.09242801279772485,
      "grad_norm": 1.1664479970932007,
      "learning_rate": 4.769818698897974e-05,
      "loss": 0.5331,
      "step": 260
    },
    {
      "epoch": 0.09953785993601137,
      "grad_norm": 2.852839708328247,
      "learning_rate": 4.752044081052258e-05,
      "loss": 0.5373,
      "step": 280
    },
    {
      "epoch": 0.10664770707429791,
      "grad_norm": 1.4390132427215576,
      "learning_rate": 4.734269463206542e-05,
      "loss": 0.4918,
      "step": 300
    },
    {
      "epoch": 0.11375755421258443,
      "grad_norm": 0.8085677027702332,
      "learning_rate": 4.716494845360825e-05,
      "loss": 0.504,
      "step": 320
    },
    {
      "epoch": 0.12086740135087096,
      "grad_norm": 1.3515349626541138,
      "learning_rate": 4.6987202275151086e-05,
      "loss": 0.4985,
      "step": 340
    },
    {
      "epoch": 0.12797724848915748,
      "grad_norm": 2.9853179454803467,
      "learning_rate": 4.680945609669392e-05,
      "loss": 0.5058,
      "step": 360
    },
    {
      "epoch": 0.135087095627444,
      "grad_norm": 1.1119409799575806,
      "learning_rate": 4.663170991823676e-05,
      "loss": 0.5251,
      "step": 380
    },
    {
      "epoch": 0.14219694276573053,
      "grad_norm": 2.218996286392212,
      "learning_rate": 4.64539637397796e-05,
      "loss": 0.4934,
      "step": 400
    },
    {
      "epoch": 0.14930678990401705,
      "grad_norm": 0.8380411863327026,
      "learning_rate": 4.6276217561322435e-05,
      "loss": 0.5062,
      "step": 420
    },
    {
      "epoch": 0.1564166370423036,
      "grad_norm": 1.2184964418411255,
      "learning_rate": 4.609847138286527e-05,
      "loss": 0.4705,
      "step": 440
    },
    {
      "epoch": 0.16352648418059013,
      "grad_norm": 1.8419673442840576,
      "learning_rate": 4.59207252044081e-05,
      "loss": 0.4617,
      "step": 460
    },
    {
      "epoch": 0.17063633131887665,
      "grad_norm": 0.8710469603538513,
      "learning_rate": 4.574297902595094e-05,
      "loss": 0.4669,
      "step": 480
    },
    {
      "epoch": 0.17774617845716317,
      "grad_norm": 2.341374635696411,
      "learning_rate": 4.5565232847493784e-05,
      "loss": 0.4734,
      "step": 500
    },
    {
      "epoch": 0.1848560255954497,
      "grad_norm": 1.3961372375488281,
      "learning_rate": 4.538748666903662e-05,
      "loss": 0.4275,
      "step": 520
    },
    {
      "epoch": 0.19196587273373622,
      "grad_norm": 0.7671663165092468,
      "learning_rate": 4.520974049057946e-05,
      "loss": 0.4501,
      "step": 540
    },
    {
      "epoch": 0.19907571987202274,
      "grad_norm": 1.1918728351593018,
      "learning_rate": 4.503199431212229e-05,
      "loss": 0.4565,
      "step": 560
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 1.951108455657959,
      "learning_rate": 4.4854248133665126e-05,
      "loss": 0.4358,
      "step": 580
    },
    {
      "epoch": 0.21329541414859582,
      "grad_norm": 1.9126518964767456,
      "learning_rate": 4.4676501955207966e-05,
      "loss": 0.5055,
      "step": 600
    },
    {
      "epoch": 0.22040526128688234,
      "grad_norm": 1.1378859281539917,
      "learning_rate": 4.44987557767508e-05,
      "loss": 0.4467,
      "step": 620
    },
    {
      "epoch": 0.22751510842516887,
      "grad_norm": 1.3176078796386719,
      "learning_rate": 4.432100959829364e-05,
      "loss": 0.4487,
      "step": 640
    },
    {
      "epoch": 0.2346249555634554,
      "grad_norm": 0.9590367674827576,
      "learning_rate": 4.4143263419836475e-05,
      "loss": 0.4601,
      "step": 660
    },
    {
      "epoch": 0.2417348027017419,
      "grad_norm": 1.1263188123703003,
      "learning_rate": 4.396551724137931e-05,
      "loss": 0.4004,
      "step": 680
    },
    {
      "epoch": 0.24884464984002844,
      "grad_norm": 3.0259041786193848,
      "learning_rate": 4.378777106292215e-05,
      "loss": 0.4706,
      "step": 700
    },
    {
      "epoch": 0.25595449697831496,
      "grad_norm": 1.1519176959991455,
      "learning_rate": 4.361002488446498e-05,
      "loss": 0.4124,
      "step": 720
    },
    {
      "epoch": 0.2630643441166015,
      "grad_norm": 1.459594964981079,
      "learning_rate": 4.3432278706007824e-05,
      "loss": 0.4326,
      "step": 740
    },
    {
      "epoch": 0.270174191254888,
      "grad_norm": 1.9175523519515991,
      "learning_rate": 4.3254532527550664e-05,
      "loss": 0.4163,
      "step": 760
    },
    {
      "epoch": 0.27728403839317456,
      "grad_norm": 1.5855793952941895,
      "learning_rate": 4.30767863490935e-05,
      "loss": 0.4222,
      "step": 780
    },
    {
      "epoch": 0.28439388553146105,
      "grad_norm": 0.794833779335022,
      "learning_rate": 4.289904017063633e-05,
      "loss": 0.4483,
      "step": 800
    },
    {
      "epoch": 0.2915037326697476,
      "grad_norm": 0.9743921160697937,
      "learning_rate": 4.2721293992179166e-05,
      "loss": 0.4172,
      "step": 820
    },
    {
      "epoch": 0.2986135798080341,
      "grad_norm": 1.1607235670089722,
      "learning_rate": 4.2543547813722007e-05,
      "loss": 0.4193,
      "step": 840
    },
    {
      "epoch": 0.30572342694632065,
      "grad_norm": 0.8774323463439941,
      "learning_rate": 4.236580163526485e-05,
      "loss": 0.3994,
      "step": 860
    },
    {
      "epoch": 0.3128332740846072,
      "grad_norm": 1.344369649887085,
      "learning_rate": 4.218805545680768e-05,
      "loss": 0.4186,
      "step": 880
    },
    {
      "epoch": 0.3199431212228937,
      "grad_norm": 1.3434733152389526,
      "learning_rate": 4.2010309278350515e-05,
      "loss": 0.4387,
      "step": 900
    },
    {
      "epoch": 0.32705296836118025,
      "grad_norm": 2.315657615661621,
      "learning_rate": 4.183256309989335e-05,
      "loss": 0.4371,
      "step": 920
    },
    {
      "epoch": 0.33416281549946675,
      "grad_norm": 1.0708812475204468,
      "learning_rate": 4.165481692143619e-05,
      "loss": 0.4391,
      "step": 940
    },
    {
      "epoch": 0.3412726626377533,
      "grad_norm": 1.3058180809020996,
      "learning_rate": 4.147707074297903e-05,
      "loss": 0.3903,
      "step": 960
    },
    {
      "epoch": 0.3483825097760398,
      "grad_norm": 3.7945749759674072,
      "learning_rate": 4.1299324564521864e-05,
      "loss": 0.4078,
      "step": 980
    },
    {
      "epoch": 0.35549235691432635,
      "grad_norm": 1.6066688299179077,
      "learning_rate": 4.1121578386064704e-05,
      "loss": 0.359,
      "step": 1000
    },
    {
      "epoch": 0.36260220405261284,
      "grad_norm": 1.3557208776474,
      "learning_rate": 4.094383220760754e-05,
      "loss": 0.339,
      "step": 1020
    },
    {
      "epoch": 0.3697120511908994,
      "grad_norm": 1.088144063949585,
      "learning_rate": 4.076608602915037e-05,
      "loss": 0.405,
      "step": 1040
    },
    {
      "epoch": 0.37682189832918594,
      "grad_norm": 0.8776066899299622,
      "learning_rate": 4.058833985069321e-05,
      "loss": 0.4101,
      "step": 1060
    },
    {
      "epoch": 0.38393174546747244,
      "grad_norm": 1.4206007719039917,
      "learning_rate": 4.041059367223605e-05,
      "loss": 0.439,
      "step": 1080
    },
    {
      "epoch": 0.391041592605759,
      "grad_norm": 1.8169053792953491,
      "learning_rate": 4.023284749377889e-05,
      "loss": 0.4009,
      "step": 1100
    },
    {
      "epoch": 0.3981514397440455,
      "grad_norm": 1.381511926651001,
      "learning_rate": 4.005510131532173e-05,
      "loss": 0.3919,
      "step": 1120
    },
    {
      "epoch": 0.40526128688233204,
      "grad_norm": 0.7764509320259094,
      "learning_rate": 3.9877355136864555e-05,
      "loss": 0.3905,
      "step": 1140
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 1.850640058517456,
      "learning_rate": 3.9699608958407396e-05,
      "loss": 0.4399,
      "step": 1160
    },
    {
      "epoch": 0.4194809811589051,
      "grad_norm": 0.9605478644371033,
      "learning_rate": 3.952186277995023e-05,
      "loss": 0.36,
      "step": 1180
    },
    {
      "epoch": 0.42659082829719164,
      "grad_norm": 2.3109841346740723,
      "learning_rate": 3.934411660149307e-05,
      "loss": 0.4127,
      "step": 1200
    },
    {
      "epoch": 0.43370067543547813,
      "grad_norm": 2.190322160720825,
      "learning_rate": 3.916637042303591e-05,
      "loss": 0.3582,
      "step": 1220
    },
    {
      "epoch": 0.4408105225737647,
      "grad_norm": 1.1412220001220703,
      "learning_rate": 3.8988624244578745e-05,
      "loss": 0.3758,
      "step": 1240
    },
    {
      "epoch": 0.4479203697120512,
      "grad_norm": 0.780918300151825,
      "learning_rate": 3.881087806612158e-05,
      "loss": 0.3745,
      "step": 1260
    },
    {
      "epoch": 0.45503021685033773,
      "grad_norm": 2.642225980758667,
      "learning_rate": 3.863313188766441e-05,
      "loss": 0.4192,
      "step": 1280
    },
    {
      "epoch": 0.46214006398862423,
      "grad_norm": 0.9988794326782227,
      "learning_rate": 3.845538570920725e-05,
      "loss": 0.3833,
      "step": 1300
    },
    {
      "epoch": 0.4692499111269108,
      "grad_norm": 1.899388074874878,
      "learning_rate": 3.8277639530750094e-05,
      "loss": 0.3747,
      "step": 1320
    },
    {
      "epoch": 0.4763597582651973,
      "grad_norm": 1.5987651348114014,
      "learning_rate": 3.809989335229293e-05,
      "loss": 0.4385,
      "step": 1340
    },
    {
      "epoch": 0.4834696054034838,
      "grad_norm": 1.3011363744735718,
      "learning_rate": 3.792214717383577e-05,
      "loss": 0.3907,
      "step": 1360
    },
    {
      "epoch": 0.4905794525417704,
      "grad_norm": 1.5865840911865234,
      "learning_rate": 3.77444009953786e-05,
      "loss": 0.4162,
      "step": 1380
    },
    {
      "epoch": 0.4976892996800569,
      "grad_norm": 2.425752639770508,
      "learning_rate": 3.7566654816921436e-05,
      "loss": 0.4672,
      "step": 1400
    },
    {
      "epoch": 0.5047991468183434,
      "grad_norm": 2.072936773300171,
      "learning_rate": 3.7388908638464276e-05,
      "loss": 0.4078,
      "step": 1420
    },
    {
      "epoch": 0.5119089939566299,
      "grad_norm": 1.0972703695297241,
      "learning_rate": 3.721116246000711e-05,
      "loss": 0.3725,
      "step": 1440
    },
    {
      "epoch": 0.5190188410949165,
      "grad_norm": 1.8581269979476929,
      "learning_rate": 3.703341628154995e-05,
      "loss": 0.3949,
      "step": 1460
    },
    {
      "epoch": 0.526128688233203,
      "grad_norm": 1.4831383228302002,
      "learning_rate": 3.6855670103092785e-05,
      "loss": 0.4161,
      "step": 1480
    },
    {
      "epoch": 0.5332385353714895,
      "grad_norm": 1.6369318962097168,
      "learning_rate": 3.667792392463562e-05,
      "loss": 0.3708,
      "step": 1500
    },
    {
      "epoch": 0.540348382509776,
      "grad_norm": 0.930073082447052,
      "learning_rate": 3.650017774617846e-05,
      "loss": 0.3421,
      "step": 1520
    },
    {
      "epoch": 0.5474582296480626,
      "grad_norm": 1.626429796218872,
      "learning_rate": 3.632243156772129e-05,
      "loss": 0.3918,
      "step": 1540
    },
    {
      "epoch": 0.5545680767863491,
      "grad_norm": 0.9180271029472351,
      "learning_rate": 3.6144685389264134e-05,
      "loss": 0.44,
      "step": 1560
    },
    {
      "epoch": 0.5616779239246357,
      "grad_norm": 0.9206374883651733,
      "learning_rate": 3.5966939210806974e-05,
      "loss": 0.3622,
      "step": 1580
    },
    {
      "epoch": 0.5687877710629221,
      "grad_norm": 1.165183186531067,
      "learning_rate": 3.578919303234981e-05,
      "loss": 0.3812,
      "step": 1600
    },
    {
      "epoch": 0.5758976182012087,
      "grad_norm": 1.0601145029067993,
      "learning_rate": 3.561144685389264e-05,
      "loss": 0.4248,
      "step": 1620
    },
    {
      "epoch": 0.5830074653394952,
      "grad_norm": 1.371669054031372,
      "learning_rate": 3.5433700675435476e-05,
      "loss": 0.3866,
      "step": 1640
    },
    {
      "epoch": 0.5901173124777818,
      "grad_norm": 1.3417136669158936,
      "learning_rate": 3.5255954496978316e-05,
      "loss": 0.3977,
      "step": 1660
    },
    {
      "epoch": 0.5972271596160682,
      "grad_norm": 2.421628475189209,
      "learning_rate": 3.507820831852116e-05,
      "loss": 0.3989,
      "step": 1680
    },
    {
      "epoch": 0.6043370067543548,
      "grad_norm": 1.0142625570297241,
      "learning_rate": 3.490046214006399e-05,
      "loss": 0.3507,
      "step": 1700
    },
    {
      "epoch": 0.6114468538926413,
      "grad_norm": 0.9237031936645508,
      "learning_rate": 3.4722715961606825e-05,
      "loss": 0.3335,
      "step": 1720
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 2.014084815979004,
      "learning_rate": 3.4544969783149665e-05,
      "loss": 0.3788,
      "step": 1740
    },
    {
      "epoch": 0.6256665481692144,
      "grad_norm": 1.0171840190887451,
      "learning_rate": 3.43672236046925e-05,
      "loss": 0.376,
      "step": 1760
    },
    {
      "epoch": 0.6327763953075008,
      "grad_norm": 0.8917628526687622,
      "learning_rate": 3.418947742623534e-05,
      "loss": 0.4302,
      "step": 1780
    },
    {
      "epoch": 0.6398862424457874,
      "grad_norm": 1.4104104042053223,
      "learning_rate": 3.4011731247778174e-05,
      "loss": 0.4253,
      "step": 1800
    },
    {
      "epoch": 0.646996089584074,
      "grad_norm": 1.0352703332901,
      "learning_rate": 3.3833985069321014e-05,
      "loss": 0.4027,
      "step": 1820
    },
    {
      "epoch": 0.6541059367223605,
      "grad_norm": 1.7382806539535522,
      "learning_rate": 3.365623889086385e-05,
      "loss": 0.3594,
      "step": 1840
    },
    {
      "epoch": 0.6612157838606469,
      "grad_norm": 1.5045217275619507,
      "learning_rate": 3.347849271240668e-05,
      "loss": 0.3861,
      "step": 1860
    },
    {
      "epoch": 0.6683256309989335,
      "grad_norm": 2.591618776321411,
      "learning_rate": 3.330074653394952e-05,
      "loss": 0.3598,
      "step": 1880
    },
    {
      "epoch": 0.67543547813722,
      "grad_norm": 0.9221744537353516,
      "learning_rate": 3.3123000355492357e-05,
      "loss": 0.3525,
      "step": 1900
    },
    {
      "epoch": 0.6825453252755066,
      "grad_norm": 1.1288682222366333,
      "learning_rate": 3.29452541770352e-05,
      "loss": 0.3393,
      "step": 1920
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.796082079410553,
      "learning_rate": 3.276750799857803e-05,
      "loss": 0.4202,
      "step": 1940
    },
    {
      "epoch": 0.6967650195520796,
      "grad_norm": 1.6573890447616577,
      "learning_rate": 3.2589761820120865e-05,
      "loss": 0.3477,
      "step": 1960
    },
    {
      "epoch": 0.7038748666903661,
      "grad_norm": 1.433719515800476,
      "learning_rate": 3.2412015641663706e-05,
      "loss": 0.3723,
      "step": 1980
    },
    {
      "epoch": 0.7109847138286527,
      "grad_norm": 1.4435986280441284,
      "learning_rate": 3.223426946320654e-05,
      "loss": 0.3191,
      "step": 2000
    },
    {
      "epoch": 0.7180945609669392,
      "grad_norm": 0.8651378750801086,
      "learning_rate": 3.205652328474938e-05,
      "loss": 0.3783,
      "step": 2020
    },
    {
      "epoch": 0.7252044081052257,
      "grad_norm": 1.5924466848373413,
      "learning_rate": 3.187877710629222e-05,
      "loss": 0.4241,
      "step": 2040
    },
    {
      "epoch": 0.7323142552435122,
      "grad_norm": 1.26629638671875,
      "learning_rate": 3.1701030927835054e-05,
      "loss": 0.3888,
      "step": 2060
    },
    {
      "epoch": 0.7394241023817988,
      "grad_norm": 1.3199198246002197,
      "learning_rate": 3.152328474937789e-05,
      "loss": 0.3551,
      "step": 2080
    },
    {
      "epoch": 0.7465339495200853,
      "grad_norm": 0.8771263360977173,
      "learning_rate": 3.134553857092073e-05,
      "loss": 0.3619,
      "step": 2100
    },
    {
      "epoch": 0.7536437966583719,
      "grad_norm": 1.4992789030075073,
      "learning_rate": 3.116779239246356e-05,
      "loss": 0.3877,
      "step": 2120
    },
    {
      "epoch": 0.7607536437966583,
      "grad_norm": 2.1355843544006348,
      "learning_rate": 3.0990046214006403e-05,
      "loss": 0.3627,
      "step": 2140
    },
    {
      "epoch": 0.7678634909349449,
      "grad_norm": 1.0398621559143066,
      "learning_rate": 3.081230003554924e-05,
      "loss": 0.3599,
      "step": 2160
    },
    {
      "epoch": 0.7749733380732314,
      "grad_norm": 1.4472126960754395,
      "learning_rate": 3.063455385709207e-05,
      "loss": 0.4337,
      "step": 2180
    },
    {
      "epoch": 0.782083185211518,
      "grad_norm": 3.1476705074310303,
      "learning_rate": 3.0456807678634912e-05,
      "loss": 0.3403,
      "step": 2200
    },
    {
      "epoch": 0.7891930323498044,
      "grad_norm": 2.305680990219116,
      "learning_rate": 3.0279061500177746e-05,
      "loss": 0.3977,
      "step": 2220
    },
    {
      "epoch": 0.796302879488091,
      "grad_norm": 1.0217777490615845,
      "learning_rate": 3.0101315321720586e-05,
      "loss": 0.4371,
      "step": 2240
    },
    {
      "epoch": 0.8034127266263775,
      "grad_norm": 2.3298981189727783,
      "learning_rate": 2.992356914326342e-05,
      "loss": 0.3691,
      "step": 2260
    },
    {
      "epoch": 0.8105225737646641,
      "grad_norm": 1.4344621896743774,
      "learning_rate": 2.9745822964806257e-05,
      "loss": 0.3508,
      "step": 2280
    },
    {
      "epoch": 0.8176324209029506,
      "grad_norm": 2.031064748764038,
      "learning_rate": 2.9568076786349098e-05,
      "loss": 0.4228,
      "step": 2300
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 1.1673235893249512,
      "learning_rate": 2.9390330607891932e-05,
      "loss": 0.3633,
      "step": 2320
    },
    {
      "epoch": 0.8318521151795236,
      "grad_norm": 1.6462939977645874,
      "learning_rate": 2.921258442943477e-05,
      "loss": 0.3833,
      "step": 2340
    },
    {
      "epoch": 0.8389619623178102,
      "grad_norm": 1.4582219123840332,
      "learning_rate": 2.9034838250977603e-05,
      "loss": 0.3933,
      "step": 2360
    },
    {
      "epoch": 0.8460718094560967,
      "grad_norm": 0.9047335982322693,
      "learning_rate": 2.8857092072520444e-05,
      "loss": 0.3628,
      "step": 2380
    },
    {
      "epoch": 0.8531816565943833,
      "grad_norm": 1.8330357074737549,
      "learning_rate": 2.867934589406328e-05,
      "loss": 0.3677,
      "step": 2400
    },
    {
      "epoch": 0.8602915037326697,
      "grad_norm": 1.3967269659042358,
      "learning_rate": 2.8501599715606115e-05,
      "loss": 0.367,
      "step": 2420
    },
    {
      "epoch": 0.8674013508709563,
      "grad_norm": 1.7471779584884644,
      "learning_rate": 2.8323853537148952e-05,
      "loss": 0.3704,
      "step": 2440
    },
    {
      "epoch": 0.8745111980092428,
      "grad_norm": 1.072501540184021,
      "learning_rate": 2.8146107358691786e-05,
      "loss": 0.4,
      "step": 2460
    },
    {
      "epoch": 0.8816210451475294,
      "grad_norm": 0.7759273648262024,
      "learning_rate": 2.7968361180234626e-05,
      "loss": 0.3634,
      "step": 2480
    },
    {
      "epoch": 0.8887308922858158,
      "grad_norm": 0.8852407336235046,
      "learning_rate": 2.7790615001777464e-05,
      "loss": 0.3876,
      "step": 2500
    },
    {
      "epoch": 0.8958407394241024,
      "grad_norm": 1.2144765853881836,
      "learning_rate": 2.7612868823320297e-05,
      "loss": 0.4284,
      "step": 2520
    },
    {
      "epoch": 0.9029505865623889,
      "grad_norm": 3.2081377506256104,
      "learning_rate": 2.7435122644863138e-05,
      "loss": 0.4065,
      "step": 2540
    },
    {
      "epoch": 0.9100604337006755,
      "grad_norm": 1.4727665185928345,
      "learning_rate": 2.7257376466405975e-05,
      "loss": 0.3664,
      "step": 2560
    },
    {
      "epoch": 0.917170280838962,
      "grad_norm": 2.292118549346924,
      "learning_rate": 2.707963028794881e-05,
      "loss": 0.4091,
      "step": 2580
    },
    {
      "epoch": 0.9242801279772485,
      "grad_norm": 2.3991222381591797,
      "learning_rate": 2.690188410949165e-05,
      "loss": 0.383,
      "step": 2600
    },
    {
      "epoch": 0.931389975115535,
      "grad_norm": 1.3821744918823242,
      "learning_rate": 2.672413793103448e-05,
      "loss": 0.3787,
      "step": 2620
    },
    {
      "epoch": 0.9384998222538216,
      "grad_norm": 1.5862141847610474,
      "learning_rate": 2.654639175257732e-05,
      "loss": 0.3893,
      "step": 2640
    },
    {
      "epoch": 0.9456096693921081,
      "grad_norm": 0.7071366906166077,
      "learning_rate": 2.636864557412016e-05,
      "loss": 0.4362,
      "step": 2660
    },
    {
      "epoch": 0.9527195165303946,
      "grad_norm": 1.4360531568527222,
      "learning_rate": 2.6190899395662992e-05,
      "loss": 0.3656,
      "step": 2680
    },
    {
      "epoch": 0.9598293636686811,
      "grad_norm": 1.0107733011245728,
      "learning_rate": 2.6013153217205833e-05,
      "loss": 0.3882,
      "step": 2700
    },
    {
      "epoch": 0.9669392108069677,
      "grad_norm": 1.8579351902008057,
      "learning_rate": 2.5835407038748667e-05,
      "loss": 0.3817,
      "step": 2720
    },
    {
      "epoch": 0.9740490579452542,
      "grad_norm": 1.146830677986145,
      "learning_rate": 2.5657660860291504e-05,
      "loss": 0.3733,
      "step": 2740
    },
    {
      "epoch": 0.9811589050835408,
      "grad_norm": 1.4748070240020752,
      "learning_rate": 2.5479914681834344e-05,
      "loss": 0.3849,
      "step": 2760
    },
    {
      "epoch": 0.9882687522218272,
      "grad_norm": 0.9669974446296692,
      "learning_rate": 2.5302168503377178e-05,
      "loss": 0.3541,
      "step": 2780
    },
    {
      "epoch": 0.9953785993601137,
      "grad_norm": 0.6511044502258301,
      "learning_rate": 2.5124422324920015e-05,
      "loss": 0.3563,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3670271337032318,
      "eval_runtime": 341.9805,
      "eval_samples_per_second": 14.621,
      "eval_steps_per_second": 0.915,
      "step": 2813
    }
  ],
  "logging_steps": 20,
  "max_steps": 5626,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3031636654080000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
